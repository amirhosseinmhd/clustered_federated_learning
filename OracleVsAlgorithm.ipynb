{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplified Algorithm \n",
    "\n",
    "Step 1: Initialize model parameters $\\hat{w}$.  \n",
    "Step 2: Randomly choose a set $C := {i_1, ..., i_B} \\subseteq {2, ..., n}$.  \n",
    "Step 3: For each $i' \\in C$, compute:  \n",
    "$\\tilde{w}^{(i')} := \\hat{w} - \\eta \\nabla L_{i'}(\\hat{w})$  \n",
    "Step 4: For each $i' \\in C$, compute loss $\\ell_{i'} = L_1(\\tilde{w}^{(i')})$.  \n",
    "Step 5: Determine candidate $i_0 \\in C$ with smallest loss:  \n",
    "$\\ell_{i_0} = \\min_{i' \\in C} \\ell_{i'}$  \n",
    "Step 6: Update $\\hat{w}$ via step 3 for $i' = i_0$.  \n",
    "Step 7: If the stopping criterion is not met, continue with step 2.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "HM6ZzXU3-lQL"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "import copy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dE2y0hpq-lQM"
   },
   "source": [
    "## CONFIG Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "id5yIgFz-lQM"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "###########\n",
    "FLAG_TRAIN_ALL_TASKS = False # If this be -1 all of nodes start updating they parameters.\n",
    "# As the parameters of each node does not aggregate in the algorithm we can only select a sample of client and see their performance.\n",
    "NUM_SAMPLED_NODES = 10 # Number of clients that start updating their parameters\n",
    "\n",
    "\n",
    "SUBSET_SIZE = 25 # |B|\n",
    "\n",
    "NUM_SAMPLES = 10 #m_i = m\n",
    "dm = 10 # d/m this parameters is dimensionality of local datasets to number of their traning samples\n",
    "NUM_FEATURES = int(NUM_SAMPLES * dm)\n",
    "STD = 0.01 # Standard Deviation of the Noise\n",
    "NUM_CLUSTERS = 2  \n",
    "NUM_CLIENTS = 200\n",
    "NUM_ROUNDS = 3000 # Stopping Crietria\n",
    "LEARNING_RATE = 0.01\n",
    "NUM_RUNS = 3 # Total number of runs that we have. In each run the true underlying vector will be reinitialized\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_true_underlying_w(num_features):\n",
    "    '''\n",
    "    This function initilized the true undelying vector for each client and their cluster identity.\n",
    "    '''\n",
    "    one_hotted_GT = torch.from_numpy(np.eye(NUM_CLUSTERS)[np.random.choice(NUM_CLUSTERS,\n",
    "                                                                           NUM_CLIENTS)].T)  # creates a matrix and indicates which client belongs to which cluster it has k rows and n coloumns\n",
    "    core_GT_weights = torch.from_numpy(np.random.uniform(low=-10, high=10, size=(num_features, NUM_CLUSTERS)))  # (d, k)\n",
    "    clients_GT_weights = core_GT_weights @ one_hotted_GT  # (d, n) = (d, k) @ (k, n)\n",
    "\n",
    "    return one_hotted_GT, clients_GT_weights\n",
    "\n",
    "\n",
    "class Client:\n",
    "    def __init__(self, num_samples, num_features, weights, true_w, STD):\n",
    "        self.weights = weights\n",
    "\n",
    "        self.X, self.y = generate_data(num_samples, num_features,\n",
    "                                       true_w, STD)\n",
    "        self.GT_w = true_w\n",
    "\n",
    "    def get_local_loss(self, weights):\n",
    "        prediction = self.X @ weights\n",
    "        loss_ = ((prediction - self.y) ** 2).mean()\n",
    "        return loss_\n",
    "\n",
    "    def train_locally(self, L, lr):\n",
    "        '''\n",
    "        Given number of iteration L, this method will update parameters of the client for L iterations\n",
    "        '''\n",
    "        weights = self.weights.clone()\n",
    "        for l in range(0, L):\n",
    "            weights.requires_grad_()\n",
    "            weights.grad = None\n",
    "            prediction = self.X @ weights\n",
    "            loss_ = ((prediction - self.y) ** 2).mean()\n",
    "            loss_.backward()\n",
    "            grad = weights.grad.clone()\n",
    "            with torch.no_grad():\n",
    "                weights = weights - lr * grad\n",
    "        self.weights = weights.detach()\n",
    "        return weights.detach()\n",
    "\n",
    "    def eval(self, weights):\n",
    "        '''\n",
    "        Evaluation is done based on deviation of estimated parameters from true underlying vector.\n",
    "        '''\n",
    "        with torch.no_grad():\n",
    "            return ((self.GT_w - weights).norm(p=2)).item()\n",
    "\n",
    "\n",
    "def generate_data(num_samples, num_features, true_w, STD):\n",
    "    \"\"\"Generate synthetic data for a user.\"\"\"\n",
    "    X = torch.randn(num_samples, num_features, dtype=torch.float64)\n",
    "    y = X @ true_w + STD * torch.randn(num_samples, 1)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def get_clients_list(num_features, clients_GT_weights):\n",
    "    '''\n",
    "    This function returns a list which has clients initial\n",
    "    '''\n",
    "    w_init_mat = torch.randn(num_features, NUM_CLIENTS, requires_grad=False, dtype=torch.float64)\n",
    "    clients_list = []\n",
    "    for client_iter in range(NUM_CLIENTS):\n",
    "        GT_w = clients_GT_weights[:, client_iter].reshape(-1, 1)\n",
    "        w = w_init_mat[:, client_iter].reshape(-1, 1).clone()\n",
    "        clients_list.append(Client(NUM_SAMPLES, num_features, w, GT_w, STD))\n",
    "    return clients_list\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11UKd8x3-lQM"
   },
   "source": [
    "## ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_w_candidate(current_weight, X, y, lr):\n",
    "    '''\n",
    "    Finds proposed parameters - w_candidate - from a candidate.\n",
    "    '''\n",
    "    current_weight.requires_grad_()\n",
    "    current_weight.grad = None\n",
    "    prediction = X @ current_weight\n",
    "    loss_ = ((prediction - y) ** 2).mean()\n",
    "    loss_.backward()\n",
    "    with torch.no_grad():\n",
    "        w_candidate = current_weight - lr * current_weight.grad\n",
    "    return w_candidate\n",
    "\n",
    "def get_w_candidates(clients_list, curr_client_id, num_features, client_ids, lr):\n",
    "    '''\n",
    "    for user 1 (see the paper) here we find candidate parameters as a matrix called \"candidates\" which each candidates[:, i] refers to a set of parameters proposed by a candidate i.\n",
    "    Here is the procedure:\n",
    "    We will give the function some client ids as input which corresponds to id of the candidates in clients list.\n",
    "    The goal of this function is to find parameters that each candidate will propose to update client 1's parameter\n",
    "    '''\n",
    "    curr_weight = clients_list[curr_client_id].weights.clone()\n",
    "    candidates = torch.zeros((num_features, SUBSET_SIZE), dtype=torch.float64)\n",
    "    for iter_client in range(SUBSET_SIZE):\n",
    "        id_ = client_ids[iter_client]\n",
    "        client = clients_list[id_]\n",
    "        w_iter = find_w_candidate(curr_weight.clone(), client.X, client.y, lr)\n",
    "        candidates[:, iter_client] = w_iter.clone().squeeze()\n",
    "    return candidates\n",
    "\n",
    "\n",
    "def get_w_with_best_reward(num_features, candidates, client_ids, client):\n",
    "    '''\n",
    "    here we find the best candidate parameters from the matrix candidates which incurr the minimum loss among candidates on user 1's validation loss.\n",
    "    '''\n",
    "    current_loss = client.get_local_loss(client.weights)\n",
    "    rewards = torch.empty((SUBSET_SIZE), dtype=torch.float64)\n",
    "    for iter_client in range(SUBSET_SIZE):\n",
    "        rewards[iter_client] = current_loss - client.get_local_loss(candidates[:, iter_client].reshape(num_features, 1))\n",
    "    idx_max_reward = torch.argmax(rewards)\n",
    "    return candidates[:, idx_max_reward], client_ids[idx_max_reward].item(), rewards[idx_max_reward].item()\n",
    "\n",
    "\n",
    "def get_random_indices_without_i():\n",
    "    '''\n",
    "    here we sample B candidates which we make use of to update client 1's parameters\n",
    "    '''\n",
    "    indices = np.arange(0, NUM_CLIENTS)\n",
    "    total_client_ids = np.empty((SUBSET_SIZE, NUM_CLIENTS), dtype=int)\n",
    "\n",
    "    for iter_client in range(NUM_CLIENTS):\n",
    "        available_indices = np.delete(indices, iter_client)\n",
    "        random_indices = np.random.choice(available_indices, size=SUBSET_SIZE, replace=False)\n",
    "        total_client_ids[:, iter_client] = random_indices\n",
    "    return total_client_ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binding different functions into main function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "18chSmpO-lQM"
   },
   "outputs": [],
   "source": [
    "def algorithm(clients_list, num_features, num_rounds, lr, sampled_clients, training_all_tasks=1):\n",
    "    \n",
    "    mat_history_rewards = np.empty((num_rounds, NUM_CLIENTS))\n",
    "    mat_history_idx_best_candid = np.empty((num_rounds, NUM_CLIENTS), dtype=int)\n",
    "    hist_loss = np.empty((num_rounds, NUM_CLIENTS))\n",
    "    hist_loss_valid = np.empty((num_rounds, NUM_CLIENTS))\n",
    "    norm_grad = np.empty((num_rounds, NUM_CLIENTS))\n",
    "    print(\"Starting Training of Algorithm\")\n",
    "\n",
    "    for round_ in range(num_rounds):\n",
    "        total_subsets = get_random_indices_without_i()\n",
    "        w_mat = torch.zeros((num_features, NUM_CLIENTS), dtype=torch.float64)\n",
    "        if round_ % 100 == 0: \n",
    "            print(f\"Current Round is {round_}\")\n",
    "        for iter_client in range(NUM_CLIENTS):\n",
    "            if (not training_all_tasks) and (iter_client not in sampled_clients):\n",
    "                continue # here we only train subset of nodes to reduce the computational burden\n",
    "            curr_client_candidates = get_w_candidates(clients_list, iter_client, num_features,\n",
    "                                                      total_subsets[:, iter_client], lr)\n",
    "\n",
    "            w_mat[:, iter_client], mat_history_idx_best_candid[round_, iter_client], mat_history_rewards[round_,\n",
    "            iter_client] = get_w_with_best_reward(num_features,\n",
    "                                                  curr_client_candidates, total_subsets[:, iter_client],\n",
    "                                                  clients_list[iter_client])\n",
    "\n",
    "            grad = w_mat[:, iter_client].reshape(-1, 1) - clients_list[iter_client].weights\n",
    "            norm_grad[round_, iter_client] = np.linalg.norm(grad)\n",
    "\n",
    "        loss = []\n",
    "        loss_valid = []\n",
    "\n",
    "        for iter_client in range(NUM_CLIENTS):\n",
    "            loss.append(clients_list[iter_client].eval(clients_list[iter_client].weights.detach()))\n",
    "            loss_valid.append(clients_list[iter_client].get_local_loss(clients_list[iter_client].weights.detach()).item())\n",
    "            clients_list[iter_client].weights = w_mat[:, iter_client].clone().reshape(-1, 1)\n",
    "        hist_loss[round_, :] = loss\n",
    "        hist_loss_valid[round_, :] = loss_valid\n",
    "    return mat_history_rewards, mat_history_idx_best_candid, hist_loss, hist_loss_valid, norm_grad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oracle Algorithm\n",
    "\n",
    "Here we have oracle algorithm which selects clients candidate from correct cluster randomly each round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "_7cE6jjy-lQN"
   },
   "outputs": [],
   "source": [
    "\n",
    "def oracle_algo(clients_list, one_hotted_gt, lr, sampled_clients, training_all_tasks=-1):\n",
    "    # we want to sample gradients from each cluster then compare with our.\n",
    "\n",
    "    num_clusters = one_hotted_gt.shape[0]\n",
    "    indices = np.argmax(one_hotted_gt, axis=0)\n",
    "    num_features = clients_list[0].X.shape[1]\n",
    "    w_mat = torch.zeros((num_features, NUM_CLIENTS), dtype=torch.float64)\n",
    "\n",
    "    hist_loss = np.empty((NUM_ROUNDS, NUM_CLIENTS))\n",
    "    hist_loss_valid = np.empty((NUM_ROUNDS, NUM_CLIENTS))\n",
    "    print(\"Starting Training in for Oracle\")\n",
    "    for round_ in range(NUM_ROUNDS):\n",
    "        if round_ % 100 == 0:\n",
    "            print(f\"Current Round is {round_}\")\n",
    "        for iter_client in range(NUM_CLIENTS):\n",
    "            if (not training_all_tasks) and (iter_client not in sampled_clients):\n",
    "                continue\n",
    "            client_cluster = indices[iter_client].item()\n",
    "            temp_available_clients = indices == client_cluster\n",
    "            available_clients = [i for i,flag in zip(clients_list,temp_available_clients) if flag] # Here we select clients randomly from correct cluster for user 1\n",
    "            candidate = random.sample(available_clients, 1)[0]\n",
    "            curr_w = clients_list[iter_client].weights.clone()\n",
    "            w_mat[:, iter_client] = find_w_candidate(curr_w, candidate.X, candidate.y, lr).squeeze().clone()\n",
    "\n",
    "        loss = []\n",
    "        loss_valid = []\n",
    "        for iter_client in range(NUM_CLIENTS):\n",
    "            loss.append(clients_list[iter_client].eval(clients_list[iter_client].weights.detach()))\n",
    "            loss_valid.append(clients_list[iter_client].get_local_loss(clients_list[iter_client].weights.detach()).item())\n",
    "            clients_list[iter_client].weights = w_mat[:, iter_client].clone().reshape(-1, 1)\n",
    "        hist_loss[round_, :] = loss\n",
    "        hist_loss_valid[round_, :] = loss_valid\n",
    "\n",
    "    return hist_loss, hist_loss_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "TUvKFnoq-lQN"
   },
   "outputs": [],
   "source": [
    "def change_clients_w_init(clients_list, w_init_mat):\n",
    "\n",
    "    for client_iter in range(NUM_CLIENTS):\n",
    "        clients_list[client_iter].weights = w_init_mat[:, client_iter].reshape(-1, 1)\n",
    "    return clients_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_objects(directory, *args):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    frame = inspect.currentframe().f_back\n",
    "    for i, obj in enumerate(args, start=1):\n",
    "        var_name = None\n",
    "        for name, value in frame.f_locals.items():\n",
    "            if value is obj:\n",
    "                var_name = name\n",
    "                break\n",
    "        if var_name is None:\n",
    "            var_name = f'object_{i}'\n",
    "        filename = os.path.join(directory, f'{var_name}.pkl')\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(obj, f)\n",
    "        print(f'Object {i} pickled and saved as {filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub Optimal Oracle\n",
    "\n",
    "Here we select candidate only from the correct cluster, then among candaidates we select a candidate that incurs minimum loss on local validation dataset. The goal is to see if there was no chance that it select from another cluster how well it would work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oracle_algo_suboptimal(clients_list, one_hotted_gt, lr, sampled_clients, training_all_tasks=-1):\n",
    "    # we want to sample gradients from each cluster then compare with our.\n",
    "\n",
    "    num_clusters = one_hotted_gt.shape[0]\n",
    "    indices = np.argmax(one_hotted_gt, axis=0)\n",
    "    num_features = clients_list[0].X.shape[1]\n",
    "    w_mat = torch.zeros((num_features, NUM_CLIENTS), dtype=torch.float64)\n",
    "\n",
    "    hist_loss = np.empty((NUM_ROUNDS, NUM_CLIENTS))\n",
    "    hist_loss_valid = np.empty((NUM_ROUNDS, NUM_CLIENTS))\n",
    "    print(\"Starting Training in for Oracle\")\n",
    "    for round_ in range(NUM_ROUNDS):\n",
    "        if round_ % 100 == 0:\n",
    "            print(f\"Current Round is {round_}\")\n",
    "        for iter_client in range(NUM_CLIENTS):\n",
    "            if (not training_all_tasks) and (iter_client not in sampled_clients):\n",
    "                continue\n",
    "            client_cluster = indices[iter_client].item()\n",
    "            temp_available_clients = indices == client_cluster\n",
    "            # available_clients = [i for i,flag in zip(clients_list,temp_available_clients) if flag] # Here we select clients randomly from correct cluster for user 1\n",
    "            candidate_ids_from_same_cluster = np.arange(0, len(temp_available_clients))[temp_available_clients]\n",
    "\n",
    "            sampled_candidate_ids = np.random.choice(candidate_ids_from_same_cluster, size=SUBSET_SIZE, replace=False)\n",
    "            # From here we have the algorithm, we just changed the candidates from random selected to correct selected\n",
    "\n",
    "            curr_client_candidates = get_w_candidates(clients_list, iter_client, num_features,\n",
    "                                                      sampled_candidate_ids, lr)\n",
    "\n",
    "            w_mat[:, iter_client], _, _ = get_w_with_best_reward(num_features,\n",
    "                                                  curr_client_candidates, sampled_candidate_ids,\n",
    "                                                  clients_list[iter_client])\n",
    "\n",
    "\n",
    "\n",
    "        loss = []\n",
    "        loss_valid = []\n",
    "        for iter_client in range(NUM_CLIENTS):\n",
    "            loss.append(clients_list[iter_client].eval(clients_list[iter_client].weights.detach()))\n",
    "            loss_valid.append(clients_list[iter_client].get_local_loss(clients_list[iter_client].weights.detach()).item())\n",
    "            clients_list[iter_client].weights = w_mat[:, iter_client].clone().reshape(-1, 1)\n",
    "        hist_loss[round_, :] = loss\n",
    "        hist_loss_valid[round_, :] = loss_valid\n",
    "\n",
    "    return hist_loss, hist_loss_valid\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8UqtqgOu-lQN"
   },
   "source": [
    "## PUTTING EVERYTHING TOGETHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0nwBWLh5-lQN",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________\n",
      "Run Number 0\n",
      "Starting Training of Algorithm\n",
      "Current Round is 0\n",
      "Current Round is 100\n",
      "Current Round is 200\n",
      "Current Round is 300\n",
      "Current Round is 400\n",
      "Current Round is 500\n",
      "Current Round is 600\n",
      "Current Round is 700\n",
      "Current Round is 800\n",
      "Current Round is 900\n",
      "Current Round is 1000\n",
      "Current Round is 1100\n",
      "Current Round is 1200\n",
      "Current Round is 1300\n",
      "Current Round is 1400\n",
      "Current Round is 1500\n",
      "Current Round is 1600\n",
      "Current Round is 1700\n",
      "Current Round is 1800\n",
      "Current Round is 1900\n",
      "Current Round is 2000\n",
      "Current Round is 2100\n",
      "Current Round is 2200\n",
      "Current Round is 2300\n",
      "Current Round is 2400\n",
      "Current Round is 2500\n",
      "Current Round is 2600\n",
      "Current Round is 2700\n",
      "Current Round is 2800\n",
      "Current Round is 2900\n",
      "Starting Training in for Oracle\n",
      "Current Round is 0\n",
      "Current Round is 100\n",
      "Current Round is 200\n",
      "Current Round is 300\n",
      "Current Round is 400\n",
      "Current Round is 500\n",
      "Current Round is 600\n",
      "Current Round is 700\n",
      "Current Round is 800\n",
      "Current Round is 900\n",
      "Current Round is 1000\n",
      "Current Round is 1100\n",
      "Current Round is 1200\n",
      "Current Round is 1300\n",
      "Current Round is 1400\n",
      "Current Round is 1500\n",
      "Current Round is 1600\n",
      "Current Round is 1700\n",
      "Current Round is 1800\n",
      "Current Round is 1900\n",
      "Current Round is 2000\n",
      "Current Round is 2100\n",
      "Current Round is 2200\n",
      "Current Round is 2300\n",
      "Current Round is 2400\n",
      "Current Round is 2500\n",
      "Current Round is 2600\n",
      "Current Round is 2700\n",
      "Current Round is 2800\n",
      "Current Round is 2900\n",
      "Starting Training in for Oracle\n",
      "Current Round is 0\n",
      "Current Round is 100\n",
      "Current Round is 200\n",
      "Current Round is 300\n",
      "Current Round is 400\n",
      "Current Round is 500\n",
      "Current Round is 600\n",
      "Current Round is 700\n",
      "Current Round is 800\n",
      "Current Round is 900\n",
      "Current Round is 1000\n",
      "Current Round is 1100\n",
      "Current Round is 1200\n",
      "Current Round is 1300\n",
      "Current Round is 1400\n",
      "Current Round is 1500\n",
      "Current Round is 1600\n",
      "Current Round is 1700\n",
      "Current Round is 1800\n",
      "Current Round is 1900\n",
      "Current Round is 2000\n",
      "Current Round is 2100\n",
      "Current Round is 2200\n",
      "Current Round is 2300\n",
      "Current Round is 2400\n",
      "Current Round is 2500\n",
      "Current Round is 2600\n",
      "Current Round is 2700\n",
      "Current Round is 2800\n",
      "Current Round is 2900\n",
      "__________________________________\n",
      "Run Number 1\n",
      "Starting Training of Algorithm\n",
      "Current Round is 0\n",
      "Current Round is 100\n",
      "Current Round is 200\n",
      "Current Round is 300\n",
      "Current Round is 400\n",
      "Current Round is 500\n",
      "Current Round is 600\n",
      "Current Round is 700\n",
      "Current Round is 800\n",
      "Current Round is 900\n",
      "Current Round is 1000\n",
      "Current Round is 1100\n",
      "Current Round is 1200\n",
      "Current Round is 1300\n",
      "Current Round is 1400\n",
      "Current Round is 1500\n",
      "Current Round is 1600\n",
      "Current Round is 1700\n",
      "Current Round is 1800\n",
      "Current Round is 1900\n",
      "Current Round is 2000\n",
      "Current Round is 2100\n",
      "Current Round is 2200\n",
      "Current Round is 2300\n",
      "Current Round is 2400\n",
      "Current Round is 2500\n",
      "Current Round is 2600\n",
      "Current Round is 2700\n",
      "Current Round is 2800\n",
      "Current Round is 2900\n",
      "Starting Training in for Oracle\n",
      "Current Round is 0\n",
      "Current Round is 100\n",
      "Current Round is 200\n",
      "Current Round is 300\n",
      "Current Round is 400\n",
      "Current Round is 500\n",
      "Current Round is 600\n",
      "Current Round is 700\n",
      "Current Round is 800\n",
      "Current Round is 900\n",
      "Current Round is 1000\n",
      "Current Round is 1100\n",
      "Current Round is 1200\n",
      "Current Round is 1300\n",
      "Current Round is 1400\n",
      "Current Round is 1500\n",
      "Current Round is 1600\n",
      "Current Round is 1700\n",
      "Current Round is 1800\n",
      "Current Round is 1900\n",
      "Current Round is 2000\n",
      "Current Round is 2100\n",
      "Current Round is 2200\n",
      "Current Round is 2300\n",
      "Current Round is 2400\n",
      "Current Round is 2500\n",
      "Current Round is 2600\n",
      "Current Round is 2700\n",
      "Current Round is 2800\n",
      "Current Round is 2900\n",
      "Starting Training in for Oracle\n",
      "Current Round is 0\n",
      "Current Round is 100\n",
      "Current Round is 200\n",
      "Current Round is 300\n",
      "Current Round is 400\n",
      "Current Round is 500\n",
      "Current Round is 600\n",
      "Current Round is 700\n",
      "Current Round is 800\n",
      "Current Round is 900\n",
      "Current Round is 1000\n",
      "Current Round is 1100\n",
      "Current Round is 1200\n",
      "Current Round is 1300\n",
      "Current Round is 1400\n",
      "Current Round is 1500\n",
      "Current Round is 1600\n",
      "Current Round is 1700\n",
      "Current Round is 1800\n",
      "Current Round is 1900\n",
      "Current Round is 2000\n",
      "Current Round is 2100\n",
      "Current Round is 2200\n",
      "Current Round is 2300\n",
      "Current Round is 2400\n",
      "Current Round is 2500\n",
      "Current Round is 2600\n",
      "Current Round is 2700\n",
      "Current Round is 2800\n",
      "Current Round is 2900\n",
      "__________________________________\n",
      "Run Number 2\n",
      "Starting Training of Algorithm\n",
      "Current Round is 0\n",
      "Current Round is 100\n",
      "Current Round is 200\n",
      "Current Round is 300\n",
      "Current Round is 400\n",
      "Current Round is 500\n",
      "Current Round is 600\n",
      "Current Round is 700\n",
      "Current Round is 800\n",
      "Current Round is 900\n",
      "Current Round is 1000\n",
      "Current Round is 1100\n",
      "Current Round is 1200\n",
      "Current Round is 1300\n",
      "Current Round is 1400\n",
      "Current Round is 1500\n",
      "Current Round is 1600\n",
      "Current Round is 1700\n",
      "Current Round is 1800\n",
      "Current Round is 1900\n",
      "Current Round is 2000\n",
      "Current Round is 2100\n",
      "Current Round is 2200\n",
      "Current Round is 2300\n",
      "Current Round is 2400\n",
      "Current Round is 2500\n",
      "Current Round is 2600\n",
      "Current Round is 2700\n",
      "Current Round is 2800\n",
      "Current Round is 2900\n",
      "Starting Training in for Oracle\n",
      "Current Round is 0\n",
      "Current Round is 100\n",
      "Current Round is 200\n",
      "Current Round is 300\n",
      "Current Round is 400\n",
      "Current Round is 500\n",
      "Current Round is 600\n",
      "Current Round is 700\n",
      "Current Round is 800\n",
      "Current Round is 900\n",
      "Current Round is 1000\n",
      "Current Round is 1100\n",
      "Current Round is 1200\n",
      "Current Round is 1300\n",
      "Current Round is 1400\n",
      "Current Round is 1500\n",
      "Current Round is 1600\n",
      "Current Round is 1700\n",
      "Current Round is 1800\n",
      "Current Round is 1900\n",
      "Current Round is 2000\n",
      "Current Round is 2100\n",
      "Current Round is 2200\n",
      "Current Round is 2300\n",
      "Current Round is 2400\n",
      "Current Round is 2500\n",
      "Current Round is 2600\n",
      "Current Round is 2700\n",
      "Current Round is 2800\n",
      "Current Round is 2900\n",
      "Starting Training in for Oracle\n",
      "Current Round is 0\n",
      "Current Round is 100\n",
      "Current Round is 200\n",
      "Current Round is 300\n",
      "Current Round is 400\n",
      "Current Round is 500\n",
      "Current Round is 600\n",
      "Current Round is 700\n",
      "Current Round is 800\n",
      "Current Round is 900\n",
      "Current Round is 1000\n",
      "Current Round is 1100\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import inspect\n",
    "import os\n",
    "\n",
    "ONE_HOTTED_GT, CLIENT_GT_WEIGHT = create_true_underlying_w(NUM_FEATURES)\n",
    "\n",
    "hist_MSE_w = np.empty((NUM_RUNS, NUM_ROUNDS, NUM_CLIENTS))\n",
    "hist_MSE_y = np.empty((NUM_RUNS, NUM_ROUNDS, NUM_CLIENTS))\n",
    "\n",
    "hist_MSE_w_oracle = np.empty((NUM_RUNS, NUM_ROUNDS, NUM_CLIENTS))\n",
    "hist_MSE_y_oracle = np.empty((NUM_RUNS, NUM_ROUNDS, NUM_CLIENTS))\n",
    "\n",
    "\n",
    "\n",
    "hist_MSE_w_oracle_suboptimal = np.empty((NUM_RUNS, NUM_ROUNDS, NUM_CLIENTS))\n",
    "hist_MSE_y_oracle_suboptimal = np.empty((NUM_RUNS, NUM_ROUNDS, NUM_CLIENTS))\n",
    "\n",
    "\n",
    "sampled_nodes_idx = np.random.choice(np.arange(NUM_CLIENTS), size=NUM_SAMPLED_NODES, replace=False)\n",
    "\n",
    "for iter_run in range(NUM_RUNS):\n",
    "    print(\"__________________________________\")\n",
    "    print(f\"Run Number {iter_run}\")\n",
    "    \n",
    "    clients_ls_orig = get_clients_list(NUM_FEATURES, CLIENT_GT_WEIGHT)\n",
    "    clients_ls = copy.deepcopy(clients_ls_orig)\n",
    "    _, _, hist_loss_w, hist_loss_valid, _ = algorithm(clients_ls,\n",
    "                                                     NUM_FEATURES,\n",
    "                                                     NUM_ROUNDS,\n",
    "                                                     LEARNING_RATE,\n",
    "                                                    sampled_nodes_idx,\n",
    "                                                      FLAG_TRAIN_ALL_TASKS\n",
    "                                                      )\n",
    "    clients_ls = copy.deepcopy(clients_ls_orig)\n",
    "    hist_MSE_w_oracle[iter_run, :, :], hist_MSE_y_oracle[iter_run, :, :] = oracle_algo(clients_ls,\n",
    "                                                                                       ONE_HOTTED_GT,\n",
    "                                                                                       LEARNING_RATE,\n",
    "                                                                                       sampled_nodes_idx,                             \n",
    "                                                                                      FLAG_TRAIN_ALL_TASKS)\n",
    "\n",
    "    clients_ls = copy.deepcopy(clients_ls_orig)\n",
    "    hist_MSE_w_oracle_suboptimal[iter_run, :, :], hist_MSE_y_oracle_suboptimal[iter_run, :, :] = oracle_algo_suboptimal(clients_ls,\n",
    "                                                                                       ONE_HOTTED_GT,\n",
    "                                                                                       LEARNING_RATE,\n",
    "                                                                                       sampled_nodes_idx,                             \n",
    "                                                                                      FLAG_TRAIN_ALL_TASKS)\n",
    "\n",
    "    hist_MSE_w[iter_run, :, :] = hist_loss_w\n",
    "    hist_MSE_y[iter_run, :, :] = hist_loss_valid\n",
    "\n",
    "    # pickle_objects(\"saved_var\", hist_MSE_y, hist_MSE_w,  hist_MSE_y_oracle, hist_MSE_w_oracle)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FLAG_TRAIN_ALL_TASKS != -1:\n",
    "    #mean across different runs\n",
    "    mean_hist_MSE_w= hist_MSE_w.mean(axis=0)\n",
    "    mean_hist_MSE_y = hist_MSE_y.mean(axis=0)\n",
    "    \n",
    "    # getting the inspected node\n",
    "    mean_hist_MSE_w = mean_hist_MSE_w[:, sampled_nodes_idx].mean(axis=1)\n",
    "    mean_hist_MSE_y = mean_hist_MSE_y[:, sampled_nodes_idx].mean(axis=1)\n",
    "    \n",
    "    mean_hist_MSE_w_oracle = hist_MSE_w_oracle.mean(axis=0)\n",
    "    mean_hist_MSE_y_oracle = hist_MSE_y_oracle.mean(axis=0)\n",
    "    \n",
    "    mean_hist_MSE_w_oracle = mean_hist_MSE_w_oracle[:, sampled_nodes_idx].mean(axis=1)\n",
    "    mean_hist_MSE_y_oracle = mean_hist_MSE_y_oracle[:, sampled_nodes_idx].mean(axis=1)\n",
    "\n",
    "    mean_hist_MSE_w_oracle_suboptimal = hist_MSE_w_oracle_suboptimal.mean(axis=0)\n",
    "    mean_hist_MSE_y_oracle_suboptimal = hist_MSE_y_oracle_suboptimal.mean(axis=0)\n",
    "    \n",
    "    mean_hist_MSE_w_oracle_suboptimal = mean_hist_MSE_w_oracle_suboptimal[:, sampled_nodes_idx].mean(axis=1)\n",
    "    mean_hist_MSE_y_oracle_suboptimal = mean_hist_MSE_y_oracle_suboptimal[:, sampled_nodes_idx].mean(axis=1)\n",
    "else:\n",
    "    mean_hist_MSE_w= hist_MSE_w.mean(axis=0)\n",
    "    mean_hist_MSE_y = hist_MSE_y.mean(axis=0)\n",
    "    \n",
    "    mean_hist_MSE_w= mean_hist_MSE_w.mean(axis=1)\n",
    "    mean_hist_MSE_y = mean_hist_MSE_y.mean(axis=1)\n",
    "    \n",
    "    mean_hist_MSE_w_oracle = hist_MSE_w_oracle.mean(axis=0)\n",
    "    mean_hist_MSE_y_oracle = hist_MSE_y_oracle.mean(axis=0)\n",
    "    \n",
    "    mean_hist_MSE_w_oracle = mean_hist_MSE_w_oracle.mean(axis=1)\n",
    "    mean_hist_MSE_y_oracle = mean_hist_MSE_y_oracle.mean(axis=1)\n",
    "    \n",
    "    mean_hist_MSE_w_oracle_suboptimal = hist_MSE_w_oracle_suboptimal.mean(axis=0)\n",
    "    mean_hist_MSE_y_oracle_suboptimal = hist_MSE_y_oracle_suboptimal.mean(axis=0)\n",
    "    \n",
    "    mean_hist_MSE_w_oracle_suboptimal = mean_hist_MSE_w_oracle_suboptimal.mean(axis=1)\n",
    "    mean_hist_MSE_y_oracle_suboptimal = mean_hist_MSE_y_oracle_suboptimal.mean(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QREqhc6g-lQO"
   },
   "source": [
    "#### Deviation from True Underlying Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pmUw7xST-lQO"
   },
   "outputs": [],
   "source": [
    "x = np.arange(NUM_ROUNDS)\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "plt.plot(x, mean_hist_MSE_w, label='Algorithm')\n",
    "plt.plot(x, mean_hist_MSE_w_oracle, label='Oracle Optimal')\n",
    "plt.plot(x, mean_hist_MSE_w_oracle_suboptimal, label='Oracle Sub Optimal')\n",
    "\n",
    "plt.xlabel(\"Rounds\")\n",
    "plt.ylabel(\"E{${||\\overline{w}^{(i)} - \\hat{w}^{(i)} ||^2_2} $}\", fontsize=12)\n",
    "plt.title(\"Algorithm vs Oracle\")\n",
    "fig.text(0.5, 0.001, f\"The Candidate Set Size for Algorithm is Fixed to {SUBSET_SIZE}, and The $d/m$ is {dm}. Number of clients is {NUM_CLIENTS} and Number of Clusters is {NUM_CLUSTERS}\",\n",
    "         horizontalalignment=\"center\")\n",
    "plt.grid(True)  #\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U0XKJ3Ak-lQO"
   },
   "outputs": [],
   "source": [
    "x = np.arange(NUM_ROUNDS)\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "plt.plot(x, mean_hist_MSE_y, label='Algorithm')\n",
    "plt.plot(x, mean_hist_MSE_y_oracle, label='Oracle')\n",
    "plt.plot(x, mean_hist_MSE_y_oracle_suboptimal, label='Oracle Sub Optimal')\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"Rounds\")\n",
    "plt.ylabel(\"E{${||{y}^{(i)} - \\hat{y}^{(i)} ||^2_2} $}\", fontsize=12)\n",
    "plt.title(\"Algorithm vs Oracle\")\n",
    "fig.text(0.5, 0.001, f\"The Candidate Set Size for Algorithm is Fixed to {SUBSET_SIZE}, and The $d/m$ is {dm}. Number of clients is {NUM_CLIENTS} and Number of Clusters is {NUM_CLUSTERS}\",\n",
    "         horizontalalignment=\"center\")\n",
    "plt.grid(True)  #\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Fork of compare_subset_size",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
